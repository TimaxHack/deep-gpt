import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor
from tempfile import NamedTemporaryFile

import aiofiles
from aiogram import Router
from aiogram.types import Message, CallbackQuery
from openai import OpenAI

from bot.agreement import agreement_handler
from bot.filters import TextCommand, Document, Photo, TextCommandQuery, Voice
from bot.gpt import change_model_command
from bot.gpt.command_types import change_system_message_command, change_system_message_text, change_model_text, \
    balance_text, balance_command, clear_command, clear_text
from bot.gpt.system_messages import get_system_message, system_messages_list, \
    create_system_message_keyboard
from bot.gpt.utils import is_chat_member, send_message, get_tokens_message, \
    create_change_model_keyboard, checked_text
from bot.utils import include
from config import TOKEN, GO_API_KEY
from services import gptService, GPTModels, completionsService, tokenizeService
from services.gpt_service import SystemMessages
from services.image_utils import format_image_from_request
from services.utils import async_post, async_get
from bot.utils import send_photo_as_file

gptRouter = Router()

questionAnswer = False

async def handle_gpt_request(message: Message, text: str):
    user_id = message.from_user.id
    message_loading = await message.answer("**‚åõÔ∏è–û–∂–∏–¥–∞–π—Ç–µ –æ—Ç–≤–µ—Ç...**")

    try:
        is_agreement = await agreement_handler(message)

        if not is_agreement:
            return

        is_subscribe = await is_chat_member(message)

        if not is_subscribe:
            return

        chat_id = message.chat.id

        bot_model = gptService.get_current_model(user_id)
        gpt_model = gptService.get_mapping_gpt_model(user_id)

        await message.bot.send_chat_action(chat_id, "typing")

        system_message = gptService.get_current_system_message(user_id)

        gpt_tokens_before = await tokenizeService.get_tokens(user_id)

        if gpt_tokens_before.get("tokens", 0) <= 0:
            await message.answer(
                text=f"""
–û—à–∏–±–∫–∞ üòî: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è!

/balance - ‚ú® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–∞–ª–∞–Ω—Å
/buy - üíé –ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å 
/referral - –ü—Ä–∏–≥–ª–∞—Å–∏—Ç—å –¥—Ä—É–≥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ `energy` ‚ö°!
/model - –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
""")
            return
        system_message = get_system_message(system_message)
        if system_message == "question-answer":
            questionAnswer = True
        else:
            questionAnswer = False
        answer = await completionsService.query_chatgpt(
            user_id,
            text,
            system_message,
            gpt_model,
            bot_model,
            questionAnswer,
        )

        print(answer)

        if not answer.get("success"):
            if answer.get('response') == "–û—à–∏–±–∫–∞ üòî: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤.":
                await message.answer(
                    text=f"""
{answer.get('response')}

/balance - ‚ú® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–∞–ª–∞–Ω—Å
/buy - üíé –ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å 
/referral - –ü—Ä–∏–≥–ª–∞—Å–∏—Ç—å –¥—Ä—É–≥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ `energy`‚ö°!
/model - –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
""",
                )
                await asyncio.sleep(0.5)
                await message_loading.delete()

                return

            await message.answer(answer.get('response'))
            await asyncio.sleep(0.5)
            await message_loading.delete()

            return

        gpt_tokens_after = await tokenizeService.get_tokens(user_id)

        format_text = format_image_from_request(answer.get("response"))
        image = format_text["image"]

        await send_message(message, format_text["text"])
        if image is not None:
            await message.answer_photo(image)
            await send_photo_as_file(message, image, "–í–æ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∞ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–µ")
        await asyncio.sleep(0.5)
        await message_loading.delete()
        await message.answer(get_tokens_message(gpt_tokens_before.get("tokens", 0) - gpt_tokens_after.get("tokens", 0)))
    except Exception as e:
        logging.log(logging.INFO, e)


@gptRouter.message(Photo())
async def handle_document(message: Message):
    tokens = await tokenizeService.get_tokens(message.from_user.id)

    if tokens.get("tokens") <= 0:
        await message.answer("""
–£ –≤–∞—Å –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç `energy` ‚ö°!

/balance - ‚ú® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–∞–ª–∞–Ω—Å
/buy - üíé –ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å
/referral - –ü—Ä–∏–≥–ª–∞—Å–∏—Ç—å –¥—Ä—É–≥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ `energy`‚ö°!    
""")
        return

    is_subscribe = await is_chat_member(message)

    if not is_subscribe:
        return

    file_info = await message.bot.get_file(message.photo[-1].file_id)

    openai = OpenAI(
        api_key=GO_API_KEY,
        base_url="https://api.goapi.xyz/v1/",
    )

    text = "–û–ø–∏—à–∏ —ç—Ç—É —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é" if message.caption is None else message.caption

    await message.bot.send_chat_action(message.chat.id, "typing")

    file_url = f"https://api.telegram.org/file/bot{TOKEN}/{file_info.file_path}"

    chat_completion = openai.chat.completions.create(
        model="gpt-4o",
        max_tokens=4096,
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": text},
                    {"type": "image_url", "image_url": {"url": file_url}},
                ]
            },
        ],
        stream=False,
    )

    tokens = chat_completion.usage.total_tokens * 3

    await message.bot.send_chat_action(message.chat.id, "typing")

    await tokenizeService.update_user_token(message.from_user.id, tokens, 'subtract')

    content = chat_completion.choices[0].message.content

    await message.bot.send_chat_action(message.chat.id, "typing")

    await send_message(message, content)
    await message.answer(get_tokens_message(tokens))


async def transcribe_voice_sync(voice_file_url: str):
    headers = {
        "Authorization": f"Bearer {GO_API_KEY}",
    }

    voice_response = await async_get(voice_file_url)
    if voice_response.status_code == 200:
        voice_data = voice_response.content

        files = {
            'file': ('audio.ogg', voice_data, 'audio/ogg'),
            'model': (None, 'whisper-1')
        }

        post_response = await async_post("https://api.goapi.ai/v1/audio/transcriptions", headers=headers, files=files)
        if post_response.status_code == 200:
            return {"success": True, "text": post_response.json()["text"]}
        else:
            return {"success": False, "text": f"Error: {post_response.status_code}"}
    else:
        return {"success": False, "text": f"Error: {voice_response.status_code}"}


executor = ThreadPoolExecutor()


async def transcribe_voice(voice_file_url: str):
    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(executor, transcribe_voice_sync, voice_file_url)
    return await response


@gptRouter.message(Voice())
async def handle_voice(message: Message):
    tokens = await tokenizeService.get_tokens(message.from_user.id)

    if tokens.get("tokens") <= 0:
        await message.answer("""
–£ –≤–∞—Å –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç `energy` ‚ö° 

/balance - ‚ú® –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ë–∞–ª–∞–Ω—Å
/buy - üíé –ü–æ–ø–æ–ª–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å
/referral - –ü—Ä–∏–≥–ª–∞—Å–∏—Ç—å –¥—Ä—É–≥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–µ—Å–ø–ª–∞—Ç–Ω–æ `energy` ‚ö°!  
""")
        return

    is_subscribe = await is_chat_member(message)

    if not is_subscribe:
        return

    duration = message.voice.duration
    voice_file_id = message.voice.file_id
    file = await message.bot.get_file(voice_file_id)
    file_url = f"https://api.telegram.org/file/bot{TOKEN}/{file.file_path}"

    response_json = await transcribe_voice(file_url)

    tokens = duration * 30
    if response_json.get("success"):
        await message.answer(f"""
üé§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –∑–∞—Ç—Ä–∞—Ç–∏–ª–∞ `{tokens}` `energy` ‚ö° 

‚ùî /help - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ `energy` ‚ö°
""")
        await tokenizeService.update_user_token(message.from_user.id, tokens, 'subtract')

        await handle_gpt_request(message, response_json.get('text'))
        return

    await message.answer(response_json.get('text'))


@gptRouter.message(Document())
async def handle_document(message: Message):
    try:
        user_document = message.document if message.document else None
        if user_document:
            with NamedTemporaryFile(delete=False) as temp_file:
                await message.bot.download(user_document, temp_file.name)
            async with aiofiles.open(temp_file.name, 'r', encoding='utf-8') as file:
                text = await file.read()
                caption = message.caption if message.caption is not None else ""
                await handle_gpt_request(message, f"{caption}\n{text}")
    except UnicodeDecodeError as e:
        logging.log(logging.INFO, e)
        await message.answer(
            """
            üòî –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–æ–≤ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è!
            
–°–ª–µ–¥–∏—Ç–µ –∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –≤ –∫–∞–Ω–∞–ª–µ @gptDeep
            """)
    except Exception as e:
        logging.log(logging.INFO, e)


@gptRouter.message(TextCommand([balance_text(), balance_command()]))
async def handle_balance(message: Message):
    await tokenizeService.check_tokens_update_tokens(message.from_user.id)
    gpt_tokens = await tokenizeService.get_tokens(message.from_user.id)

    await message.answer(f"""
üíµ –¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å: 

*{gpt_tokens.get("tokens")}* `energy` ‚ö° 
""")


@gptRouter.message(TextCommand([clear_command(), clear_text()]))
async def handle_clear_context(message: Message):
    user_id = message.from_user.id

    hello = await tokenizeService.clear_dialog(user_id)

    if hello.get("status") == 404:
        await message.answer("–î–∏–∞–ª–æ–≥ —É–∂–µ –ø—É—Å—Ç!")
        return

    if hello is None:
        await message.answer("–û—à–∏–±–∫–∞ üòî: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç!")
        return

    await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω! üëåüèª")


@gptRouter.message(TextCommand([change_system_message_command(), change_system_message_text()]))
async def handle_change_model(message: Message):
    is_agreement = await agreement_handler(message)

    if not is_agreement:
        return

    is_subscribe = await is_chat_member(message)

    if not is_subscribe:
        return

    user_id = message.from_user.id

    current_system_message = gptService.get_current_system_message(user_id)

    if not include(system_messages_list, current_system_message):
        current_system_message = SystemMessages.Default.value
        gptService.set_current_system_message(user_id, current_system_message)

    await message.answer(
        text="–£—Å—Ç–∞–Ω–æ–≤–∏ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞: ‚öôÔ∏è",
        reply_markup=create_system_message_keyboard(current_system_message)
    )

    await asyncio.sleep(0.5)
    await message.delete()


@gptRouter.message(TextCommand([change_model_command(), change_model_text()]))
async def handle_change_model(message: Message):
    is_agreement = await agreement_handler(message)

    if not is_agreement:
        return

    is_subscribe = await is_chat_member(message)

    if not is_subscribe:
        return

    current_model = gptService.get_current_model(message.from_user.id)

    text = """
–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å: ü§ñ  

–ö–∞–∫ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è energy –¥–ª—è –º–æ–¥–µ–ª–µ–π?
1000 *GPT-4o* —Ç–æ–∫–µ–Ω–æ–≤ = 1000 `energy` ‚ö°Ô∏è
1000 *GPT-4o-mini* —Ç–æ–∫–µ–Ω–æ–≤ = 70 `energy` ‚ö°Ô∏è
1000 *GPT-3.5-turbo* —Ç–æ–∫–µ–Ω–æ–≤ = 70 `energy` ‚ö°Ô∏è

1000 *Nemotron-4-340B* —Ç–æ–∫–µ–Ω–æ–≤ = 800 `energy` ‚ö°Ô∏è

1000 *Llama-3-70B* —Ç–æ–∫–µ–Ω–æ–≤ = 285 `energy` ‚ö°Ô∏è
1000 *Qwen2-72B* —Ç–æ–∫–µ–Ω–æ–≤ = 285 `energy` ‚ö°Ô∏è
1000 *CodeLlama-70b* —Ç–æ–∫–µ–Ω–æ–≤ = 285 `energy` ‚ö°Ô∏è
1000 *WizardLM-2-8x22B* —Ç–æ–∫–µ–Ω–æ–≤ = 285 `energy` ‚ö°Ô∏è

1000 *Meta-Llama-3-8B* —Ç–æ–∫–µ–Ω–æ–≤ = 20 `energy` ‚ö°Ô∏è
1000 *WizardLM-2-7B* —Ç–æ–∫–µ–Ω–æ–≤ = 20 `energy` ‚ö°Ô∏è    
"""

    await message.answer(text=text, reply_markup=create_change_model_keyboard(current_model))
    await asyncio.sleep(0.5)
    await message.delete()


@gptRouter.callback_query(TextCommandQuery(system_messages_list))
async def handle_change_system_message_query(callback_query: CallbackQuery):
    user_id = callback_query.from_user.id

    system_message = callback_query.data
    current_system_message = gptService.get_current_system_message(user_id)

    if system_message == current_system_message:
        await callback_query.answer(f"–î–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º —É–∂–µ –≤—ã–±—Ä–∞–Ω!")
        return

    gptService.set_current_system_message(user_id, system_message)

    await callback_query.message.edit_reply_markup(
        reply_markup=create_system_message_keyboard(system_message)
    )
    if system_message != "question_answer" and current_system_message != "question_answer":
        await tokenizeService.clear_dialog(user_id)

    await asyncio.sleep(0.5)

    await callback_query.answer(f"–†–µ–∂–∏–º —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω—ë–Ω!")
    await callback_query.message.delete()


@gptRouter.callback_query(
    TextCommandQuery(list(map(lambda model: model.value, list(GPTModels)))))
async def handle_change_model_query(callback_query: CallbackQuery):
    user_id = callback_query.from_user.id

    gpt_model = GPTModels(callback_query.data)
    current_gpt_model = gptService.get_current_model(user_id)

    if gpt_model.value == current_gpt_model.value:
        await callback_query.answer(f"–ú–æ–¥–µ–ª—å {current_gpt_model.value} —É–∂–µ –≤—ã–±—Ä–∞–Ω–∞!")
        return

    gptService.set_current_model(user_id, gpt_model)

    await callback_query.message.edit_reply_markup(
        reply_markup=create_change_model_keyboard(gpt_model)
    )

    await asyncio.sleep(0.5)

    await callback_query.answer(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–º–µ–Ω–µ–Ω–∞ –Ω–∞ {checked_text(gpt_model.value)}")
    await callback_query.message.delete()


@gptRouter.message()
async def handle_completion(message: Message):
    await handle_gpt_request(message, message.text)
